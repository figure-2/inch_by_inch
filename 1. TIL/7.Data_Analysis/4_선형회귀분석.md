# 머신러닝
> 머신러닝 이론과 기본  
> 티쳐블머신 모델 생성   
> 데이터 분리(데이터세트분할)  
> 회귀_LinearRegression   
> 농어 길이로 무게 예측  

## 머신러닝 이론
### AI 용어 및 종류
- 인공지능 : 사람처럼 똑똑한 기계
- 머신러닝 : 인공지능을 구현하는데 성공한 방법, 기계학습
- 딥러닝 : 머신러닝보다 더 똑똑한 인공지능을 구현하는데 성공한 방법, 인간의 뉴런과 비슷한 인공신경망 기반

- 기계학습(머신러닝)
    - **지도 학습** : 정답을 알려주며 학습시키는 지도학습 => **분류/예측(회귀)**
    - **비지도 학습** : 정답을 알려주지 않고 규칙을 스스로 발견하는 비지도 학습 => **군집화/연관규칙**
    - **강화 학습** : 실패와 성공의 과정을 반복하며 학습해나가는 강화학습 (알파고) => **보상?**

## 머신러닝 기본
### 기계학습 모델
1. 지도학습 : 예측(회귀)
- 주어진 입력과 출력의 쌍을 학스한 후, 새로운 데이터를 입력했을 때 합리적인 출력값을 예측하는 것

2. 지도학습 : 분류
- 훈련 데이터에 각각 레이블을 지정하고 학습하여 분류

3. 비지도 학습 : 군집
- 답(레이블)없이 문제로만 학습하는 비지도 학습
- 스스로 데이터 간의 패턴을 찾아 분류 기준을 찾고, 비슷한 유형의 데이터끼리 그룹핑하면서 군집 생성

### 데이터 속성
- 피처(Feature) : 데이터 세트의 일반 속성으로 레이블을 제외한 나머지 속성을 모두 피처로 지칭
- 레이블(Label) : 데이터의 학습을 위해 주어진 정답 데이터

### 머신러닝 워크플로우
- 데이터 세트 분할
    - 훈련데이터 : 학습하기 위한 데이터
    - 테스트데이터 : 학습할 때 사용하지 않은 데이터이며 학습 완료 후 성능을 테스트 하기 위해 사용

### 언더 피팅 VS 오버 피팅
- 언더피팅(과소적합) : 학습이 부족한 상태로 지난친 단순화로 인해 에러가 많이 발생한 상태
- 오버 피팅(과대적합) : 학습이 너무 많이 된 상태로 학습 데이터에 대해 과하게 학습되어, 학급 데이터 이외의 데이터에 대해서는 잘 동작하지 못하는 상태

## 티쳐블머신 모델 생성
- [머신러닝 모델 학습 툴](https://teachablemachine.withgoogle.com/)
- 지도학습은 정답이 필요하여 label 달아주기
    - Class1 : 치와와 사진들6개 (class1은 치와와)
    - Class2 : 푸들 사진들 6개 (class2는 푸들사진으로 변경)


## 데이터 분리(데이터세트분할), 평가 척도
- 데이터분리
	- 사이킷런 설치 : `python -m pip install scikit-learn`
    - 불러오기 : `from sklearn.model_selection import train_test_split`
    - x_data, y_data 데이터 형성
    - 랜덤 데이터 추출 옵션 : `x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3)`
    - 같은 랜덤 시드 사용 같은 랜덤 데이터 추출 옵션 : `x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)`

- 회귀모델
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# 데이터 로드

x_data = np.array([
    [1, 1],
    [2, 2],
    [3, 4],
    [4, 5],
    [5, 5],
    [6, 5],
    [7, 9],
    [8, 10],
    [9, 12],
    [10, 2],
    [11, 10],
    [12, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6]) # 레이블

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777) 
# test_size=0.3 학습용(7) : 테스트용 (3) 으로 분할 
# random_state=777 동일한 학습/테스트용 데이터 세트를 생성 위해


# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
pass

# 모델 예측
x_test = np.array([
    [4, 6]
])

y_predict = model.predict(x_test)

print(y_predict[0]) #9.4827304868099
```

- 분류모델
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# 데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0])

labels = ['fail', 'pass']
# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777, stratify=y_data)

# 모델 생성
model = LogisticRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
pass

# 모델 예측
x_test = np.array([
    [4, 6]
])

y_predict = model.predict(x_test)
label = labels[y_predict[0]]
y_predict = model.predict_proba(x_test)
confidence = y_predict[0][y_predict[0].argmax()]

print(label, confidence) #
```

- 다중 분류
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# 데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([2, 2, 2, 1, 1, 2, 0, 0, 0, 1, 0, 2])

labels = ['A', 'B', 'C']

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777, stratify=y_data)

# 모델 생성
model = LogisticRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
pass

# 모델 예측
x_test = np.array([
    [4, 6]
])

y_predict = model.predict(x_test)
label = labels[y_predict[0]]
y_predict = model.predict_proba(x_test)
confidence = y_predict[0][y_predict[0].argmax()]

print(label, confidence) #

```

## 회귀
- 머신러닝 회귀 예측의 핵심은 주어진 피처와 레이블을 기반으로 학습을 통해 최적의 회귀 계수를 찾아내는 것 (회귀계수 W1,W2,...,Wn을 찾는 것).

- 선형 회귀 : 성능 아쉬움, 1차원
- 다항 회귀 : 2/3차 방정식과 같은 다항식을 쓰는 모델로 회귀선이 곡선임.

- 모델 적합 과정 (훈련을 한다는 것)
1. TrainData를 model에 input
2. 모델 learning
3. predict
4. 예측과 정답 비교해서 손실함수(RSS)가 최소??
    - 최소가 아니다.
        - 가중치와 절편 업데이트해서 input
        - learning
        - predict
        - 손실함수 최소? 반복
    - 최소이다.
        - 학습종료.

*가중치(weight)와 절편(bias using optimizer)을 업데이트함으로써 손실함수를 최소로 만들고 힉습을 종료*  

*오차가 많은데 이건 맞는 모델이고 정확도가 100%인 모델을 만들 수 없고 100%가 되었더라도 과적합되었구나라고 생각됨.*

## 농어길이로 무게 예측
1. 데이터 수집 및 확인  
    1-1. `df = pd.read_csv('path')`  
    1-2. `df.info()`   
    1-3. scatter 시각화
    ```python
    import matplotlib.pyplot as plt

    plt.scatter(fish['길이'], fish['무게'])  # 둘 간의 관계를 나타내고 2차원이다.
    plt.xlabel('length')
    plt.ylabel('weight')
    plt.show()
    ```
    1-4. EDA 툴 사용하여 결측치, 중복값 확인
    1-5. boxplot으로 이상치 확인
    
2. 모델 학습 : 단순 선형 회귀
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error , r2_score, mean_absolute_error
from sklearn.linear_model import LinearRegression

# 경고메세지 끄기
import warnings
warnings.filterwarnings(action='ignore')

# 데이터 로드
fish_df = pd.read_csv('./data/fish.csv')

# 데이터 분석
pass

# 데이터 전처리
y_data = fish_df['무게']
x_data = fish_df.drop('무게',axis=1)  # fish_df['길이']로 하면 안됨.
# print(y_data.shape, x_data.shape)

x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42) # 회귀분석


# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
print(model.score(x_train, y_train)) #0.9371680443381393
print(model.score(x_test, y_test)) #0.8324765337629763


# 모델 예측
x_test = np.array([
    [50]
])

y_predict = model.predict(x_test)

print(y_predict[0]) #1245.423930742852

#model객체에 coef_와 intercept_ 속성에 저장되어 있음
print(model.coef_ , model.intercept_)
```

**모델 결과 값**
```
0.9370169868327092
0.8320172451017457
1245.6320794533735
[39.30166945] -719.4513928072395
```

**[농어 무게 예측 방정식]**  
$y = 39.27*x - 718.43$

* coef_는 기울기, intercept_를 절편이다.
* 머신러닝에서는 기울기를 계수(coefficient) 또는 가중치(weight)라고 부른다.
* 이는 머신러닝 알고리즘이 학습을 하고 찾은 값이라는 의미로 모델 파라미터라고 부른다. 
* 많은 머신러닝 알고리즘의 훈련과정은 최적의 모델 파라미터를 찾는 것과 같다. 

3. 산점도
```python
import matplotlib.pyplot as plt

# 훈련 세트의 산점도를 그립니다
plt.scatter(x_train, y_train)

# 농어의 길이 15에서 50까지 1차 방정식 직선 그래프를 그립니다
plt.plot([15, 50], [15*model.coef_+model.intercept_, 50*model.coef_+model.intercept_])

# 50cm 농어 데이터
plt.scatter(50, 1245.42, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

**산점도 결과**
- 훈련세트에 비해서 테스트 세트의 성능이 많이 떨어지는 것을 보아 과대적합이 된 것 같다. 
- 그래프 왼쪽아래가 이상 -> 무게를 음수로 예측
- 1차 선형방정식이니 무게가 음수로 예측될 수 밖에 없으므로 좀 더 예측력을 높이기 위해 곡선인 다항 회귀로 접근필요.