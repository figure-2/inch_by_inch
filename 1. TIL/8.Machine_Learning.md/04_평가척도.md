# 평가척도
> - 회귀
>   - **MAE** : Mean Absolute Error이며 실제값과 예측값의 차이를 절댓값으로 변환해 평균한 것
>   - **MSE** : Mean Squared Error이며 실제 값과 예측값의 차이를 제곱해 평균한 것
>   - **MSLE** : MSE에 로그를 적용한 것
>   - **RMSE** : MSE에 루트를 씌운 것
>   - **RMSLE** : MLSE에 로그를 적용한 것
=> 오류값 작을수록 좋음
>   - **R^2** : 분산 기반으로 예측 성능을 평가
=> 1에 가까울 수록 예측 정확도가 높음
> - 분류
>   - **정확도(Accuracy)** : 모델이 얼마나 정확하게 분류하는지
>   - **오차행렬(Confusion Matrix)** :이진 분류의 예측 오류가 얼마인지 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타냄
>   - **정밀도(Precision)** : 예측을 Positive라고 분류한 데이터 중에서 실제로 Positive인 데이터 비율
>   - **재현율(Recall)** : 실제로 Positive인 데이터 중에서 예측이 Positive로 분류한 데이터의 비율 
>   - **F1 스코어** : 정밀도와 재현율을 결합한 지표

## 실습
### LinearRegression(회귀)
- 방법1
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

##########데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6])

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
y_predict = model.predict(x_test)
print(model.score(x_test,y_test))
print(r2_score(y_test, y_predict)) #0.8526379440119077

# 모델 예측
x_test = np.array([
    [4, 6]
])

y_predict = model.predict(x_test)

print(y_predict[0]) #8.279504382440336
```

- 방법2
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error

# 데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6])

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
y_predict = model.predict(x_test)

print('R2_train',model.score(x_train, y_train)) 
print('R2_test',model.score(x_test, y_test)) 
print('--------------------------------')
print('R2_test',r2_score(y_test, y_predict)) #0.8526379440119077
print('MSE',mean_squared_error(y_test, y_predict)) #1.694663643863061
print('RMSE',mean_squared_error(y_test,y_predict,squared=False))
print('MAE',mean_absolute_error(y_test, y_predict)) #1.010718237138116
print('MSLE',mean_squared_log_error(y_test, y_predict)) #0.05501235501698321

# 모델 예측
x_real = np.array([
    [4, 6]
])

y_pred = model.predict(x_real)

# print(y_predict[0]) #8.359902268117278
```

- 방법3
```python
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error

def evaluate_reg_all(y_test, y_predict):
    MSE = mean_squared_error(y_test,y_predict,squared=True)
    RMSE = mean_squared_error(y_test,y_predict,squared=False)  # squared=False : RMSE
    MAE = mean_absolute_error(y_test,y_predict)
    R2 = r2_score(y_test,y_predict)
    
    print(f'MSE: {MSE:.3f}, RMSE: {RMSE:.3F}, MAE: {MAE:.3F}, R^2: {R2:.3F}')
```
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error

# 데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6])

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
y_predict = model.predict(x_test)
evaluate_reg_all(y_test, y_predict) 


# 모델 예측
x_real = np.array([
    [4, 6]
])

y_pred = model.predict(x_real)

# print(y_predict[0]) #8.359902268117278
```
---
### Logistic Regression(분류)
#### 정확도(Accuracy)
```python
import numpy as np
from sklearn.metrics import accuracy_score

y_test = np.append(np.zeros(99),1) # 99개 0, 마지막 한개는 1, 완전 불균형 데이터
y_predict = np.zeros(100)

accuracy_score(y_test,y_predict) # 와우 정확도가 99% 완벽하군~~
```
#### 혼돈행렬
* 오차 행렬은 이진 뷴류의 예측 오류가 얼마인지 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다. 

* **TN**: Negative라고 예측했는데 실제도 Negative  -- 정답 (0,0)
* **TP**: Positive라고 예측했는데 실제도 Positive -- 정답 (1,1)
* **FP**: Positive라고 예측했는데 실제는 Negative -- 오답 (0,1)
* **FN**: Negative라고 예측했는데 실제는 Positive -- 오답 (1,0)

```python
import pandas as pd
# y_test = np.append(np.zeros(45),np.ones(55)) 
# y_predict = np.append(np.zeros(50),np.ones(50)) 

y_test =    [1,1,1, 0,0,0,0, 1,1, 0]
y_predict = [1,1,1, 0,0,0,0, 0,0, 1]

pd.crosstab(y_test,y_predict,
            rownames=['실제'],# 행 이름
            colnames=['예측'], # 열 이름
            margins=True # 행 열의 합 보여주기
            )  
```

#### 정밀도
- 예측을 Positive라고 분류한 데이터 중에서 실제로 Positive인 데이터 비율
```python
import pandas as pd
from sklearn.metrics import precision_score


y_test =    [1,1,1, 0,0,0,0, 0,0, 0] # 실제 정상 메일
y_predict = [1,1,1, 0,0,0,0, 0,0, 1] # 스팸으로 예측

print(f'정확도:{accuracy_score(y_test,y_predict)}')
print(f'정밀도:{precision_score(y_test,y_predict)}')
pd.crosstab(y_test,y_predict,
            rownames=['실제'],# 행 이름
            colnames=['예측'], # 열 이름
            margins=True # 행 열의 합 보여주기
            )  
정확도:0.9
정밀도:0.75
```

#### 재현율
- 실제로 Positive인 데이터 중에서 예측이 Positive로 분류한 데이터의 비율
```python
import pandas as pd
from sklearn.metrics import precision_score,recall_score

y_test =    [1,1,1, 0,0,0,0, 0,0, 1] #실제 암
y_predict = [1,1,1, 0,0,0,0, 0,0, 0] #암이 아니라고 예측

print(f'정확도:{accuracy_score(y_test,y_predict)}')
print(f'정밀도:{precision_score(y_test,y_predict)}')
print(f'재현율:{recall_score(y_test,y_predict)}')

pd.crosstab(y_test,y_predict,
            rownames=['실제'],# 행 이름
            colnames=['예측'], # 열 이름
            margins=True # 행 열의 합 보여주기
            )  

#정확도,정밀도에서 점수가 잘 나왔지만, 재현율을 통해 몹쓸 분류라는 것이 밝혀졌다.  
정확도:0.9
정밀도:1.0
재현율:0.75
```

#### F1 Score
- F1 스코어는 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가짐.(0~1사이의 값 가짐.)
```python
from sklearn.metrics import precision_score,recall_score,f1_score

y_test =    [1,1,1, 0,0,0,0, 0,0, 1] #실제 암
y_predict = [1,1,1, 0,0,0,0, 0,0, 0] #암이 아니라고 예측

print(f'정확도:{accuracy_score(y_test,y_predict)}')
print(f'정밀도:{precision_score(y_test,y_predict)}')
print(f'재현율:{recall_score(y_test,y_predict)}')
print(f'f1:{f1_score(y_test,y_predict)}')
정확도:0.9
정밀도:1.0
재현율:0.75
f1:0.8571428571428571
```

#### 분류보고서
```python
from sklearn.metrics import classification_report
y_test =    [1,1,1, 0,0,0,0, 0,0, 1] #실제 암
y_predict = [1,1,1, 0,0,0,0, 0,0, 0] #암이 아니라고 예측
target_names=['암아님','암']

print(classification_report(y_test,y_predict,target_names=target_names))

- result
              precision    recall  f1-score   support

         암아님       0.86      1.00      0.92         6
           암       1.00      0.75      0.86         4

    accuracy                           0.90        10
   macro avg       0.93      0.88      0.89        10
weighted avg       0.91      0.90      0.90        10

- 추가설명
* support: 각 클래스에 있는 관측치 개수
* macro avg: 각 클래스에 대한 지표: support를 고려하지 않음.
* weighted avg: 각 클래스의 샘플 수로 가중치를 적용하여 계산. 불균형 데이터일 경우 유용
```

