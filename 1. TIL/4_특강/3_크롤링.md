> 스크래핑 vs 웹크롤링  

> API 크롤링
- 카카오 API를 통한 크롤링
> DOM구조를 이용한 크롤링 -> 내일


## API란
url 매핑 -> API (ex. url = /user/login POST방식, GET방식)
서버에서 요청받는건 문자열(화면 구성 문자열-HTML, CSS, JS)

API를 이용해서 메뉴판을 마련해놓고 client는 API라는 메뉴에서 내가 원하는 url을 선택한 다음에 그 url을 통해서 요청을 하게됨.   
서버가 client한테 뭘 주는가?를 생각해야함.  
일단 client는 API에 있는 url를 이용하여 server한테 요청하게 됨.  
그럼 server는 client가 요청한걸 처리하고 response를 해줌.   
reponse할 때 크게 2가지를 해줌 - Page(HTML, CSS, JS), Data(XML, JSON)  
Page를 먼저 불러오고 Data를 요청하게됨(둘 다 바로 요청하는게 아님.)  
그래서 여기에 필요한건 비동기 통신!!  
동기 통신 - client -> server -> ... -> client ( client 아무것도 못함) page는 띄어놓은 거지만 Data는 채워지지 않음
비동기 통신 - client -> server -> client 할 거 하고 -> data올때 마다 그때그때 (client 자기 할 일 함)

**결론** : 서버에서 받아올 수 있는건 Page와 데이터 (HTML, CSS, JS 또는 java형식 데이터)

# 실습. 카카오 API 사용
- 카카오 API를 통해서 크롤링해서 DF만들기
- client(Python) ->(API요청)-> Server(KaKao) ->(JSON 데이터 제공)-> Client 
- 사용하기 위해서 인증키 필요함!!!!

- 앱키
    - 네이티브 앱 키 : 플레이스토어, 앱스토에서 설치하는 어플리케이션에서 카카오 서비스를 활용할 때 시용
    - REST API 키 : 웹서비스 같은데서 카카오 API를 요청하는 위한 키
    - javascript 키 : javascript환경에서 사용 가능한 키
    - admin 키 : 인증 관련된 키

## HTML, CSS, Selector
Element ,DOM 구조

## Web Crawling
- requests : json
    - 비동기 통신을 활용한 방식 (동적 페이지)
- requests : html
    - 동기 통신을 활용한 방식 (정적 페이지)
- selenium : web browser
    - 1,2번 방식으로 크롤링 불가능 할 때 사용!!
    - 무조건 모든 내용을 크롤링 할 수 있음. => 요즘 대형 포털 사이트는 막히는중
    - 하지만 매우 느리고 메모리도 많이 잡아 먹음

### 실습. 네이버 증권 크롤링
```python
import requests

url = "크롤링할 웹 페이지"

from bs4 import BeautifulSoup

res = requests.get(url)
page = res.content # # 접속한 웹 사이트의 html 코드를 가져오기

soup = soup.BeautifulSoup(page, 'html.parser') # 비동기 처리로 인해 data는 안가져옴 (bs4는 동기통신 데이터를 가져옴)
```

- 그럼 Data 어떻게 봐?
1. 개발자 도구 - Network 탭(client가 server랑 어떻게 통신하고 있는지 다 나옴)
2. Fetch/XHR(비동기 통신 내역) 클릭
3. 내가 필요한 정보를 클릭(열어서 Preview 한 번 봐야함)
4. Headers - Request URL, Request Method, content-type 확인  
```python
# 1. 웹 서비스 분석
url = "https://api.stock.naver.com/chart/domestic/index/KOSPI?periodType=dayCandle"

# 2. request, response
res = requests.get(url)
```
5. Preview에 원하는게 있는 정보에 대한 키 확인
```python
# 3. Response Header에서 content-type이 application/json인 것을 확인
#  json형식으로 데이터를 받겠구나!!
datas = res.json()["priceInfos"]
datas[:2] #2개만 확인
```
